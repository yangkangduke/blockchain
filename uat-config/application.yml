spring:
  servlet:
    multipart:
      max-file-size: 100MB
      max-request-size: 1024MB
  kafka:
    bootstrap-servers: 54.168.239.215:9092
    producer:
      retries: 3  # 生产者发送失败时，重试次数
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 生产者消息key和消息value的序列化处理类
      value-serializer: org.apache.kafka.common.serialization.StringSerializer

    consumer:
      group-id: tomge-consumer-group  # 默认消费者group id
      auto-offset-reset: earliest
      enable-auto-commit: true
      auto-commit-interval: 100
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer


redis:
  host: 54.168.239.215
  port: 6379
  password: Seeds123!

redisson:
  address: redis://${redis.host}:${redis.port}
  password: ${redis.password}
  timeout: 5000
  max-pool-size: 50
  min-idle-size: 25

file:
  bucketName: seeds # 上文创建的桶名称
  oss:
    enable: true
    endpoint: http://127.0.0.1:9000
    access-key: seeds123!
    secret-key: seeds123!

email:
  enable: false
  host: email-smtp.ap-northeast-1.amazonaws.com
  from: seeds<no-reply-dev@theseeds.io>
  user: AKIAQMKUPROLIXMNEIJK
  pass: BBTyucDgyIg8qIDU1ki5XT1x3JEZZSA3cK1FC96TO0r4

login:
  twofa: false

service:
  url:
    uc: http://127.0.0.1:10101
    admin: http://127.0.0.1:10102
    account: http://127.0.0.1:10103
    wallet: http://127.0.0.1:10104
    notification: http://127.0.0.1:10105
    game: http://127.0.0.1:10106