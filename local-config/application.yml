spring:
  servlet:
    multipart:
      max-file-size: 100MB
      max-request-size: 1024MB
  kafka:
    bootstrap-servers: 192.168.1.101:9092
    producer:
      retries: 3  # 生产者发送失败时，重试次数
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 生产者消息key和消息value的序列化处理类
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: tomge-consumer-group  # 默认消费者group id
      auto-offset-reset: latest
      enable-auto-commit: true
      auto-commit-interval: 100
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer

redis:
  host: 192.168.1.101
  port: 6379
  password: Seeds123!

redisson:
  address: redis://${redis.host}:${redis.port}
  password: ${redis.password}
  timeout: 5000
  max-pool-size: 50
  min-idle-size: 25

file:
  bucketName: seeds # 上文创建的桶名称
  oss:
    enable: true
    endpoint: http://192.168.1.101:9000
    access-key: seeds123!
    secret-key: seeds123!

email:
  enable: false
  host: email-smtp.ap-northeast-1.amazonaws.com
  from: seeds<no-reply-dev@theseeds.io>
  user: AKIAQMKUPROLIXMNEIJK
  pass: BBTyucDgyIg8qIDU1ki5XT1x3JEZZSA3cK1FC96TO0r4

login:
  twofa: true

zookeeper:
  address: 192.168.1.101:2181

service:
  url:
    uc: http://127.0.0.1:10101
    admin: http://127.0.0.1:10102
    account: http://127.0.0.1:10103
    wallet: http://127.0.0.1:10104
    notification: http://127.0.0.1:10105
    game: http://127.0.0.1:10106

mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
